{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Basic Visualization Checks</h1>\n",
    "<p>Pull up a random image to make sure everything is appearing correctly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Path\n",
    "dataDir = './data'\n",
    "dataType = 'train2017'\n",
    "annFile = f'{dataDir}/annotations/instances_{dataType}.json'\n",
    "\n",
    "# Initialize COCO\n",
    "coco = COCO(annFile)\n",
    "\n",
    "# Get Category ID for Person\n",
    "catIds = coco.getCatIds(catNms=['person'])\n",
    "\n",
    "# Get Image IDs for Person Images\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "\n",
    "# Load Random Image\n",
    "img = coco.loadImgs(imgIds[np.random.randint(0, len(imgIds))])[0]\n",
    "\n",
    "# Display Random Image\n",
    "image_path = f\"{dataDir}/{dataType}/{img['file_name']}\"\n",
    "image = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Load Image Annotations\n",
    "annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
    "anns = coco.loadAnns(annIds)\n",
    "\n",
    "# Draw Boxes\n",
    "for ann in anns:\n",
    "    bbox = ann['bbox']\n",
    "    x, y, width, height = bbox\n",
    "    cv2.rectangle(image, (int(x), int(y)), (int(x+width), int(y+height)), (255, 0, 0), 2)\n",
    "\n",
    "# Display Image with Boxes\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocess the Data</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonCocoDetection(CocoDetection):\n",
    "    def __init__(self, root, annFile, transform=None):\n",
    "        super().__init__(root, annFile, transform)\n",
    "        self.coco = COCO(annFile)\n",
    "        self.ids = self._filter_person_ids()\n",
    "\n",
    "    def _filter_person_ids(self):\n",
    "        person_ids = []\n",
    "        person_category_id = self.coco.getCatIds(catNms=['person'])[0]\n",
    "        for img_id in self.ids:\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=img_id, catIds=person_category_id, iscrowd=None)\n",
    "            if len(ann_ids) > 0:\n",
    "                person_ids.append(img_id)\n",
    "        return person_ids\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img, target = super().__getitem__(index)\n",
    "        target = [ann for ann in target if ann['category_id'] == 1]\n",
    "        return img, target\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = []\n",
    "    for item in batch:\n",
    "        target = item[1]\n",
    "        for ann in target:\n",
    "            ann['bbox'] = torchvision.ops.box_convert(torch.tensor(ann['bbox']), 'xywh', 'xyxy').tolist()\n",
    "        new_target = {\n",
    "            'boxes': torch.tensor([ann['bbox'] for ann in target], dtype=torch.float32),\n",
    "            'labels': torch.tensor([ann['category_id'] for ann in target], dtype=torch.int64),\n",
    "            'image_id': torch.tensor([ann['image_id'] for ann in target], dtype=torch.int64),\n",
    "            'area': torch.tensor([ann['area'] for ann in target], dtype=torch.float32),\n",
    "            'iscrowd': torch.tensor([ann['iscrowd'] for ann in target], dtype=torch.int64)\n",
    "        }\n",
    "        targets.append(new_target)\n",
    "    return images, targets\n",
    "\n",
    "\n",
    "# Define Transformation\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "dataDir = './data'\n",
    "dataType = 'train2017'\n",
    "annFile = f'{dataDir}/annotations/instances_{dataType}.json'\n",
    "dataset = PersonCocoDetection(root=f'{dataDir}/{dataType}', annFile=annFile, transform = transform)\n",
    "\n",
    "# Create Subset\n",
    "subset_size = 20000  \n",
    "random_seed = 42  \n",
    "\n",
    "# Set Seed\n",
    "random.seed(random_seed)\n",
    "subset_indices = random.sample(range(len(dataset)), subset_size)\n",
    "subset = Subset(dataset, subset_indices)\n",
    "\n",
    "train_dataloader = DataLoader(subset, batch_size=16, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Selection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=True)\n",
    "\n",
    "# Input Features\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# Replace Head with Person Detection Model\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "\n",
    "# Training Parameters\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            images, targets = data\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            try:\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "                epoch_loss += losses.item()\n",
    "\n",
    "                losses.backward()\n",
    "                optimizer.step()\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                continue\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(loss=losses.item())\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_epoch_loss}\")\n",
    "\n",
    "    # Early Stop\n",
    "    if avg_epoch_loss < best_loss:\n",
    "        best_loss = avg_epoch_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {patience} epochs with no improvement.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Visualize Validation Image</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Database Path\n",
    "dataDir = './data'\n",
    "dataType = 'val2017'\n",
    "annFile = f'{dataDir}/annotations/instances_{dataType}.json'\n",
    "\n",
    "# Initialize COCO\n",
    "coco = COCO(annFile)\n",
    "\n",
    "# Get Cat IDs for Person\n",
    "catIds = coco.getCatIds(catNms=['person'])\n",
    "\n",
    "# Get Person Images\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "\n",
    "# Load Random Image\n",
    "img = coco.loadImgs(imgIds[np.random.randint(0, len(imgIds))])[0]\n",
    "\n",
    "# Display Random Image\n",
    "image_path = f\"{dataDir}/{dataType}/{img['file_name']}\"\n",
    "image = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Load Image Annotations\n",
    "annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
    "anns = coco.loadAnns(annIds)\n",
    "\n",
    "# Draw Boxes\n",
    "for ann in anns:\n",
    "    bbox = ann['bbox']\n",
    "    x, y, width, height = bbox\n",
    "    cv2.rectangle(image, (int(x), int(y)), (int(x+width), int(y+height)), (255, 0, 0), 2)\n",
    "\n",
    "# Display Image with Boxes\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model State\n",
    "model.load_state_dict(torch.load('20K_fasterrcnn_resnet50_fpn.pth'))\n",
    "\n",
    "# Set Model Device\n",
    "model.to(device)\n",
    "\n",
    "# Eval Mode\n",
    "model.eval()\n",
    "\n",
    "# Load Validation Dataset\n",
    "dataDir = './data'\n",
    "dataType = 'val2017'\n",
    "annFile = f'{dataDir}/annotations/instances_{dataType}.json'\n",
    "val_dataset = PersonCocoDetection(root=f'{dataDir}/{dataType}', annFile=annFile, transform=transform)\n",
    "\n",
    "# Create Subset\n",
    "subset_size = 10  \n",
    "random_seed = 42  \n",
    "\n",
    "# # Set Seed\n",
    "random.seed(random_seed)\n",
    "subset_indices = random.sample(range(len(val_dataset)), subset_size)\n",
    "val_subset = Subset(val_dataset, subset_indices)\n",
    "\n",
    "# Create Dataloader\n",
    "test_dataloader = DataLoader(val_subset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Evaluate Model\n",
    "with torch.no_grad():\n",
    "    print(\"Starting evaluation...\")\n",
    "    for batch_idx, (images, targets) in enumerate(tqdm(test_dataloader, desc=\"Evaluating\")):\n",
    "        print(f\"Processing batch {batch_idx+1}/{len(test_dataloader)}\")\n",
    "        \n",
    "        images = [img.to(device) for img in images]\n",
    "        print(f\"Moved images to {device}\")\n",
    "        \n",
    "        # Get Predictions\n",
    "        outputs = model(images)\n",
    "        print(\"Obtained outputs from the model\")\n",
    "\n",
    "        for i, image in enumerate(images):\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "            ax = plt.gca()\n",
    "            \n",
    "            boxes = outputs[i]['boxes'].cpu().numpy()\n",
    "            scores = outputs[i]['scores'].cpu().numpy()\n",
    "            print(f\"Image {i+1} - boxes: {len(boxes)}, scores: {len(scores)}\")\n",
    "\n",
    "            # Draw Boxes\n",
    "            for box, score in zip(boxes, scores):\n",
    "                if score > 0.5: \n",
    "                    x_min, y_min, x_max, y_max = box\n",
    "                    rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor='r', facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                    plt.text(x_min, y_min, f'{score:.2f}', color='white', fontsize=12, bbox=dict(facecolor='red', alpha=0.5))\n",
    "            \n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            print(f\"Finished displaying image {i+1} of batch {batch_idx+1}\")\n",
    "\n",
    "    print(\"Evaluation complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
